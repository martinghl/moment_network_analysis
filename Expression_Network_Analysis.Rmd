---
title: "Expression Network Analysis"
author: "Martin Li"
date: "2024-09-24"
output:
  pdf_document:
    toc: yes
    latex_engine: "xelatex"
  word_document:
    toc: yes
  html_document:
    highlight: espresso
    toc: yes
---

# Introduction

This document presents a comprehensive analysis of gene expression data comparing Ulcerative Colitis (UC) patients and Healthy Controls (HC). The analysis includes:

- Differential expression analysis using `limma`.
- Covariance matrix comparison using high-dimensional covariance tests from the `PEtests` package.
- Construction of gene co-expression networks.
- Permutation tests to compare network motifs (triangle counts).
- Exploration of alternative network metrics.
- Network analysis using WGCNA (optional).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(stringsAsFactors = FALSE)
```
```{r}
# Load all necessary packages
library(WGCNA)
library(igraph)
library(ggplot2)
library(parallel)
library(caret)
library(reshape2)
library(progress)
library(ggpubr)
library(pheatmap)
```

```{r}
# Enable multi-threading within WGCNA
enableWGCNAThreads()

# Load the data
uc_data <- read.csv('S:\\Downloads\\new_uc.csv', row.names = 1)
hc_data <- read.csv('S:\\Downloads\\new_hc.csv', row.names = 1)

# Ensure that genes (rows) are the same in both datasets
common_genes <- intersect(rownames(uc_data), rownames(hc_data))
uc_data <- uc_data[common_genes, ]
hc_data <- hc_data[common_genes, ]

# Combine the data
combined_data <- cbind(uc_data, hc_data)
combined_data[combined_data < 0] <- 0
# Create sample labels
uc_samples <- colnames(uc_data)
hc_samples <- colnames(hc_data)
group_labels <- factor(c(rep("UC", length(uc_samples)), rep("HC", length(hc_samples))))
```

### 2. Filter Genes Based on Variance
We perform the near-zero variance filtering on the combined dataset to avoid removing genes that are constant in one group but variable in the other.

```{r}
# Transpose data to have genes as columns
data_transposed <- t(combined_data)

# Identify near-zero variance genes in the combined data
nzv_genes <- nearZeroVar(data_transposed, saveMetrics = TRUE)

# Filter out near-zero variance genes
data_filtered <- data_transposed[, !nzv_genes$nzv]

# Transpose back to original format (genes as rows)
data_filtered <- t(data_filtered)

# Remove genes with NA or infinite values
data_filtered <- na.omit(data_filtered)

# Check dimensions after filtering
dim(data_filtered)

```

## 3. Split Data into UC and HC Groups
Now we split the filtered data into UC and HC groups for separate network analysis.

```{r}
# Get indices for each group
uc_indices <- which(group_labels == "UC")
hc_indices <- which(group_labels == "HC")

# Split data into UC and HC groups
uc_data_filtered <- data_filtered[, uc_indices]
hc_data_filtered <- data_filtered[, hc_indices]

# Transpose data to have samples as rows for WGCNA
datExpr_UC <- t(uc_data_filtered)
datExpr_HC <- t(hc_data_filtered)
```


## 4. Check for Good Samples and Genes in Each Group *

Before constructing the network, we need to preprocess the data according to WGCNA guidelines.

```{r}
# Combine UC and HC data: samples as rows, genes as columns
datExpr_combined <- rbind(datExpr_UC, datExpr_HC)

# Check for good samples and genes across the combined dataset
gsg_combined <- goodSamplesGenes(datExpr_combined, verbose = 3)

if (!gsg_combined$allOK) {
  # Remove bad genes and samples
  if (sum(!gsg_combined$goodGenes) > 0) {
    cat("Removed genes:", names(gsg_combined$goodGenes)[!gsg_combined$goodGenes], "\n")
    datExpr_combined <- datExpr_combined[, gsg_combined$goodGenes]
  }
  if (sum(!gsg_combined$goodSamples) > 0) {
    cat("Removed samples:", rownames(datExpr_combined)[!gsg_combined$goodSamples], "\n")
    datExpr_combined <- datExpr_combined[gsg_combined$goodSamples, ]
  }
}

# Split the cleaned data back into UC and HC groups
datExpr_UC_cleaned <- datExpr_combined[rownames(datExpr_UC), ]
datExpr_HC_cleaned <- datExpr_combined[rownames(datExpr_HC), ]

# Check dimensions
cat("Cleaned UC data dimensions:", dim(datExpr_UC_cleaned), "\n")
cat("Cleaned HC data dimensions:", dim(datExpr_HC_cleaned), "\n")

# 设置表达量阈值
expression_threshold <- 0.5

# 统计 UC 组中符合表达量阈值的基因
uc_genes_to_keep <- colnames(datExpr_UC_cleaned)[colMeans(datExpr_UC_cleaned) > expression_threshold]

# 统计 HC 组中符合表达量阈值的基因
hc_genes_to_keep <- colnames(datExpr_HC_cleaned)[colMeans(datExpr_HC_cleaned) > expression_threshold]

# 获取符合条件的基因的并集
common_genes_final <- union(uc_genes_to_keep, hc_genes_to_keep)

# 根据并集统一过滤 UC 和 HC 数据，确保维度一致
datExpr_UC_cleaned <- datExpr_UC_cleaned[, common_genes_final, drop = FALSE]
datExpr_HC_cleaned <- datExpr_HC_cleaned[, common_genes_final, drop = FALSE]

# 输出过滤后的维度，确保一致
cat("Filtered UC data shape (samples x genes):", dim(datExpr_UC_cleaned), "\n")
cat("Filtered HC data shape (samples x genes):", dim(datExpr_HC_cleaned), "\n")
```
```{r}
rm(combined_data, data_filtered, data_transposed, datExpr_combined, datExpr_HC, datExpr_UC, hc_data, hc_data_filtered, uc_data, uc_data_filtered)
```


## 5. Choose Soft-Thresholding Power for Each Group

$$
a_{ij} = |r_{ij}|^\beta
$$

$$
P(k) \propto k^{-\lambda}
$$

$$
\log P(k) = -\lambda \log k + C
$$

$$
\hat{R}^2(\beta) = 1 - \frac{\sum_{i=1}^n \left( y_i - \hat{y}_i \right)^2}{\sum_{i=1}^n \left( y_i - \bar{y} \right)^2}
$$

$$
TOM_{ij} = \frac{l_{ij} + a_{ij}}{\min(k_i, k_j) + 1 - a_{ij}}
$$

\text{where:}

- \text{$a_{ij}$} \text{ is the adjacency matrix element representing the connection strength between gene$i$and gene$j$.}
- \text{$r_{ij}$} \text{ is the Pearson or Spearman correlation coefficient between genes$i$and$j$.}
- \text{$\beta$} \text{ is the soft-thresholding power.}
- \text{$P(k)$} \text{ is the probability of a node having degree$k$.}
- \text{$\lambda$} \text{ is the scaling exponent of the power-law distribution.}
- \text{$\hat{R}^2$} \text{ is the coefficient of determination from the linear fit of$\log P(k)$versus$\log k$.}
- \text{$l_{ij} = \sum_u a_{iu} a_{uj}$} \text{ is the number of shared neighbors between nodes$i$and$j$.}
- \text{$k_i = \sum_u a_{iu}$} \text{ is the degree of node$i$.}


# 老方法暂时废弃


```{r}
gc()
### UC
# Choose a set of soft-thresholding powers
powers <- c(1:20)

# Call the network topology analysis function for UC group
sft_UC <- pickSoftThreshold(datExpr_UC_cleaned, powerVector = powers, verbose = 3, RsquaredCut = 0.8 )

# Plot the results
par(mfrow = c(1,2))
cex1 <- 0.9

# Scale-free topology fit index as a function of the soft-thresholding power
plot(sft_UC$fitIndices[,1], -sign(sft_UC$fitIndices[,3])*sft_UC$fitIndices[,2],
     xlab="Soft Threshold (power)", ylab="Scale Free Topology Model Fit, signed R^2",
     type="n", main = "Scale independence (UC)")
text(sft_UC$fitIndices[,1], -sign(sft_UC$fitIndices[,3])*sft_UC$fitIndices[,2],
     labels=powers, cex=cex1, col="red")
abline(h=0.80, col="red")

# Mean connectivity as a function of the soft-thresholding power
plot(sft_UC$fitIndices[,1], sft_UC$fitIndices[,5],
     xlab="Soft Threshold (power)", ylab="Mean Connectivity", type="n",
     main = "Mean connectivity (UC)")
text(sft_UC$fitIndices[,1], sft_UC$fitIndices[,5], labels=powers, cex=cex1, col="red")
```

```{r}
gc()
### HC
# Call the network topology analysis function for HC group
sft_HC <- pickSoftThreshold(datExpr_HC_cleaned, powerVector = powers, verbose = 3 ,RsquaredCut = 0.8)

# Plot the results
par(mfrow = c(1,2))

# Scale-free topology fit index as a function of the soft-thresholding power
plot(sft_HC$fitIndices[,1], -sign(sft_HC$fitIndices[,3])*sft_HC$fitIndices[,2],
     xlab="Soft Threshold (power)", ylab="Scale Free Topology Model Fit, signed R^2",
     type="n", main = "Scale independence (HC)")
text(sft_HC$fitIndices[,1], -sign(sft_HC$fitIndices[,3])*sft_HC$fitIndices[,2],
     labels=powers, cex=cex1, col="red")
abline(h=0.80, col="red")

# Mean connectivity as a function of the soft-thresholding power
plot(sft_HC$fitIndices[,1], sft_HC$fitIndices[,5],
     xlab="Soft Threshold (power)", ylab="Mean Connectivity", type="n",
     main = "Mean connectivity (HC)")
text(sft_HC$fitIndices[,1], sft_HC$fitIndices[,5], labels=powers, cex=cex1, col="red")
```

```{r}
#softPower_UC <- ifelse(!is.na(sft_UC$powerEstimate), sft_UC$powerEstimate, 7)
softPower_UC <- 13

cat("Chosen soft-thresholding power for UC:", softPower_UC, "\n")
softPower_HC <- ifelse(!is.na(sft_HC$powerEstimate), sft_HC$powerEstimate, 7)
# softPower_HC <- 13
cat("Chosen soft-thresholding power for HC:", softPower_HC, "\n")
```
## 6. Construct Networks for Each Group
### 6.1. UC Group Network Construction
```{r}
gc()
# 将两个数据框转换为长格式，并添加标签
datExpr_UC_long <- melt(datExpr_UC_cleaned)
datExpr_UC_long$Group <- "UC"

datExpr_HC_long <- melt(datExpr_HC_cleaned)
datExpr_HC_long$Group <- "HC"

# 合并数据
datExpr_long <- rbind(datExpr_UC_long, datExpr_HC_long)
colnames(datExpr_long) <- c("Gene", "Sample", "Expression", "Group")

# 绘制表达值的密度分布图，限制 y 轴最大值为 5
ggplot(datExpr_long, aes(x = Expression, color = Group, fill = Group)) +
  geom_density(alpha = 0.4) +  # 绘制密度图，设置透明度
  labs(title = "Density Plot of Expression Values for UC and HC Groups", 
       x = "Expression", y = "Density") +
  theme_minimal() +
  ylim(0, 1)+  # 设置 y 轴范围
  xlim(-15, 15)

```

```{r}
gc()
# Construct the adjacency matrix
adjacency_UC <- adjacency(datExpr_UC_cleaned, power = softPower_UC, type = "signed")

# Convert adjacency matrix to topological overlap matrix (TOM)
TOM_UC <- TOMsimilarity(adjacency_UC, TOMType = "signed")

# Calculate dissimilarity
dissTOM_UC <- 1 - TOM_UC

# Hierarchical clustering
geneTree_UC <- hclust(as.dist(dissTOM_UC), method = "average")

```


```{r}
gc()
# Construct the adjacency matrix
adjacency_HC <- adjacency(datExpr_HC_cleaned, power = softPower_HC, type = "signed")

# Convert adjacency matrix to topological overlap matrix (TOM)
TOM_HC <- TOMsimilarity(adjacency_HC, TOMType = "signed")

# Calculate dissimilarity
dissTOM_HC <- 1 - TOM_HC

# Hierarchical clustering
geneTree_HC <- hclust(as.dist(dissTOM_HC), method = "average")
```

```{r}
save(geneTree_UC, dissTOM_UC, datExpr_UC_cleaned, geneTree_HC, dissTOM_HC, datExpr_HC_cleaned, adjacency_HC, adjacency_UC, file = "S://network//allData_1027.RData")
```

```{r}
load("S://network//allData_1027.RData")
```

```{r}
# 转换邻接矩阵为向量 (上三角部分)
adj_values_uc <- adjacency_UC[upper.tri(adjacency_UC)]
adj_values_hc <- adjacency_HC[upper.tri(adjacency_HC)]

# 创建数据框用于绘图
adj_data <- data.frame(
  value = c(adj_values_uc, adj_values_hc),
  group = rep(c("UC", "HC"), times = c(length(adj_values_uc), length(adj_values_hc)))
)

# 设置 X 轴比例范围
x_limits <- c(0, 0.75)

# 绘制 UC 密度图
p1 <- ggplot(subset(adj_data, group == "UC"), aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  labs(title = "UC Network - Density Plot",
       x = "Adjacency Matrix Value", y = "Density") +
  scale_fill_manual(values = c("UC" = "blue")) +
  coord_cartesian(xlim = x_limits)

# 绘制 HC 密度图
p2 <- ggplot(subset(adj_data, group == "HC"), aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  theme_minimal() +
  labs(title = "HC Network - Density Plot",
       x = "Adjacency Matrix Value", y = "Density") +
  scale_fill_manual(values = c("HC" = "red")) +
  coord_cartesian(xlim = x_limits)

# 绘制 UC 直方图
p3 <- ggplot(subset(adj_data, group == "UC"), aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.5, bins = 50, position = "identity") +
  theme_minimal() +
  labs(title = "UC Network - Histogram",
       x = "Adjacency Matrix Value", y = "Count") +
  scale_fill_manual(values = c("UC" = "blue")) +
  coord_cartesian(xlim = x_limits)

# 绘制 HC 直方图
p4 <- ggplot(subset(adj_data, group == "HC"), aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.5, bins = 50, position = "identity") +
  theme_minimal() +
  labs(title = "HC Network - Histogram",
       x = "Adjacency Matrix Value", y = "Count") +
  scale_fill_manual(values = c("HC" = "red")) +
  coord_cartesian(xlim = x_limits)

# 将四个图排列成 2x2 布局
library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
```

```{r}
# R²
calculateScaleFreeFit <- function(degree_vector) {
  log_degree <- log10(degree_vector[degree_vector > 0])
  degree_counts <- table(degree_vector[degree_vector > 0])
  log_freq <- log10(as.numeric(degree_counts))
  log_degree <- log10(as.numeric(names(degree_counts)))
  model <- lm(log_freq ~ log_degree)
  summary(model)$r.squared
}
```

```{r}
library(reshape2)
library(ggplot2)
library(scales)
library(gridExtra)


# UC 组：遍历每个阈值，计算平均度数、边数和 R²，并存储结果
threshold_results_UC <- data.frame(
  Threshold = numeric(),
  Mean_Degree = numeric(),
  Edge_Count = numeric(),
  R2 = numeric()
)

for (threshold in seq(0.1, 0.9, by = 0.01)) {
  adjacency_binary <- (adjacency_UC > threshold) * 1
  
  # 计算平均度数和边的数量
  mean_degree <- mean(rowSums(adjacency_binary))
  edge_count <- sum(adjacency_binary)
  
  # 计算无标度适配指数 R²
  node_degrees <- rowSums(adjacency_binary)
  R2 <- calculateScaleFreeFit(node_degrees)
  gc()
  
  # 将结果添加到数据框中
  threshold_results_UC <- rbind(
    threshold_results_UC,
    data.frame(Threshold = threshold, Mean_Degree = mean_degree, Edge_Count = edge_count, R2 = R2)
  )
}

# 绘制平均度数 vs 阈值，添加 degree = 10 的标记线
p1 <- ggplot(threshold_results_UC, aes(x = Threshold, y = Mean_Degree)) +
  geom_line(color = "blue", size = 1) +
  geom_hline(yintercept = 10, color = "black", linetype = "dashed") +  # 添加 degree = 10 标记线
  theme_minimal() +
  labs(title = "Mean Degree vs Threshold",
       x = "Threshold", y = "Mean Degree") +
  scale_y_continuous(trans = "log10", labels = scales::comma)

# 绘制边数 vs 阈值
p2 <- ggplot(threshold_results_UC, aes(x = Threshold, y = Edge_Count)) +
  geom_line(color = "red", size = 1) +
  theme_minimal() +
  labs(title = "Edge Count vs Threshold",
       x = "Threshold", y = "Edge Count") +
  scale_y_continuous(trans = "log10", labels = scales::comma)

# 绘制 R² vs 阈值，添加 R² = 0.8 的标记线
p3 <- ggplot(threshold_results_UC, aes(x = Threshold, y = R2)) +
  geom_line(color = "green", size = 1) +
  geom_hline(yintercept = 0.8, color = "black", linetype = "dashed") +  # 添加 R² = 0.8 标记线
  theme_minimal() +
  labs(title = "R² vs Threshold",
       x = "Threshold", y = "R²") +
  scale_y_continuous(labels = scales::comma)

# 输出图像
grid.arrange(p1, p2, p3, ncol = 1)
```

```{r}
# HC 组：遍历每个阈值，计算平均度数、边数和 R²，并存储结果
threshold_results_HC <- data.frame(
  Threshold = numeric(),
  Mean_Degree = numeric(),
  Edge_Count = numeric(),
  R2 = numeric()
)

for (threshold in seq(0.1, 0.9, by = 0.01)) {
  adjacency_binary <- (adjacency_HC > threshold) * 1
  
  # 计算平均度数和边的数量
  mean_degree <- mean(rowSums(adjacency_binary))
  edge_count <- sum(adjacency_binary)
  
  # 计算无标度适配指数 R²
  node_degrees <- rowSums(adjacency_binary)
  R2 <- calculateScaleFreeFit(node_degrees)
  gc()
  
  # 将结果添加到数据框中
  threshold_results_HC <- rbind(
    threshold_results_HC,
    data.frame(Threshold = threshold, Mean_Degree = mean_degree, Edge_Count = edge_count, R2 = R2)
  )
}

# 绘制平均度数 vs 阈值，添加 degree = 10 的标记线
p1_HC <- ggplot(threshold_results_HC, aes(x = Threshold, y = Mean_Degree)) +
  geom_line(color = "blue", size = 1) +
  geom_hline(yintercept = 10, color = "black", linetype = "dashed") +  # 添加 degree = 10 标记线
  theme_minimal() +
  labs(title = "Mean Degree vs Threshold (HC Group)",
       x = "Threshold", y = "Mean Degree") +
  scale_y_continuous(trans = "log10", labels = scales::comma)

# 绘制边数 vs 阈值
p2_HC <- ggplot(threshold_results_HC, aes(x = Threshold, y = Edge_Count)) +
  geom_line(color = "red", size = 1) +
  theme_minimal() +
  labs(title = "Edge Count vs Threshold (HC Group)",
       x = "Threshold", y = "Edge Count") +
  scale_y_continuous(trans = "log10", labels = scales::comma)

# 绘制 R² vs 阈值，添加 R² = 0.8 的标记线
p3_HC <- ggplot(threshold_results_HC, aes(x = Threshold, y = R2)) +
  geom_line(color = "green", size = 1) +
  geom_hline(yintercept = 0.8, color = "black", linetype = "dashed") +  # 添加 R² = 0.8 标记线
  theme_minimal() +
  labs(title = "R² vs Threshold (HC Group)",
       x = "Threshold", y = "R²") +
  scale_y_continuous(labels = scales::comma)

# 输出图像
grid.arrange(p1_HC, p2_HC, p3_HC, ncol = 1)

```
```{r}
threshold_results_UC
threshold_results_HC
```

```{r}
threshold <- 0.4
gc()
# 设置图形布局为 1 行 2 列
par(mfrow = c(1, 2))

# UC 组的度分布
adjacency_binary_UC <- (adjacency_UC > threshold) * 1
node_degrees_UC <- rowSums(adjacency_binary_UC)
degree_distribution_UC <- table(node_degrees_UC)

plot(log10(as.numeric(names(degree_distribution_UC))), 
     log10(as.numeric(degree_distribution_UC)),
     xlab = "log10(Degree)", ylab = "log10(Frequency)",
     main = paste("UC Group Degree Distribution at Threshold", threshold),
     pch = 19, col = "blue")
rm(adjacency_binary_UC)
# HC 组的度分布
adjacency_binary_HC <- (adjacency_HC > threshold) * 1
node_degrees_HC <- rowSums(adjacency_binary_HC)
degree_distribution_HC <- table(node_degrees_HC)

plot(log10(as.numeric(names(degree_distribution_HC))), 
     log10(as.numeric(degree_distribution_HC)),
     xlab = "log10(Degree)", ylab = "log10(Frequency)",
     main = paste("HC Group Degree Distribution at Threshold", threshold),
     pch = 19, col = "red")

# 重置图形布局为单图
par(mfrow = c(1, 1))
```


```{r}
# UC network
# Create igraph object from adjacency matrix
#threshold <- 0.05
#adjacency_UC_binary <- (adjacency_UC > threshold) * 1
#adjacency_HC_binary <- (adjacency_HC > threshold) * 1
#adjacency_UC_binary <- (adjacency_UC > 0) * 1  # Binarize the adjacency matrix
#g_uc <- graph_from_adjacency_matrix(adjacency_UC_binary, mode = "undirected", diag = FALSE)
#g_uc <- simplify(g_uc)

# HC network
# Create igraph object from adjacency matrix
#adjacency_HC_binary <- (adjacency_HC > 0) * 1  # Binarize the adjacency matrix
#g_hc <- graph_from_adjacency_matrix(adjacency_HC_binary, mode = "undirected", diag = FALSE)
#g_hc <- simplify(g_hc)
```

### Define Motif Counting Function
```{r}
# # Define motif counting function
# count_motifs <- function(graph) {
#   num_nodes <- vcount(graph)
#   
#   # Initialize results
#   motif_counts <- list(
#     triangle = 0,
#     three_star = 0,
#     v_shape = 0,
#     square = 0
#   )
#   
#   if (num_nodes < 3) {
#     return(motif_counts)
#   }
#   
#   # Count triangles
#   triangle_counts <- count_triangles(graph)
#   total_triangles <- sum(triangle_counts) / 3  # Each triangle is counted three times
#   max_triangles <- choose(num_nodes, 3)        # Maximum possible number of triangles
#   motif_counts$triangle <- total_triangles / max_triangles  # Normalized triangle count
#   
#   # Degrees
#   degrees <- degree(graph)
#   
#   # Count V-shapes (paths of length 2)
#   total_vshapes <- sum(choose(degrees, 2)) - 3 * total_triangles
#   max_vshapes <- choose(num_nodes, 2) * (num_nodes - 2)   # Maximum possible number of V-shapes
#   motif_counts$v_shape <- total_vshapes / max_vshapes     # Normalized V-shape count
#   
#   # Count 3-star motifs
#   total_three_stars <- sum(choose(degrees, 3))
#   max_three_stars <- choose(num_nodes, 3) * (num_nodes - 3) # Maximum possible number of 3-stars
#   motif_counts$three_star <- total_three_stars / max_three_stars  # Normalized 3-star count
#   
#   # Count squares (four-node cycles)
#   if (num_nodes >= 4) {
#     adj <- as_adj(graph, sparse = FALSE)
#     adj2 <- adj %*% adj
#     adj2_adj2 <- adj2 * adj2
#     square_count <- sum(adj2_adj2) / 2 - sum(diag(adj2_adj2)) / 2
#     total_squares <- square_count / 8  # Each square is counted 8 times
#     max_squares <- choose(num_nodes, 4)  # Maximum possible number of squares
#     motif_counts$square <- total_squares / max_squares  # Normalized square count
#   }
#   
#   return(motif_counts)
# }

```

### Define Subgraph Sampling Function

```{r}
# # Define subgraph sampling and motif counting function
# subgraph_motif_counts_single <- function(graph, sample_size, num_samples) {
#   # Initialize progress bar
#   pb <- progress_bar$new(
#     format = "  Processing [:bar] :percent in :elapsed",
#     total = num_samples, clear = FALSE, width = 60
#   )
#   
#   # Pre-sample all node lists to minimize data transfer
#   all_sampled_nodes <- replicate(num_samples, sample(V(graph)$name, sample_size), simplify = FALSE)
#   
#   # List to store results
#   motif_counts_list <- list()
#   
#   # Loop over samples to count motifs
#   for (i in seq_len(num_samples)) {
#     sampled_nodes <- all_sampled_nodes[[i]]
#     subgraph <- induced_subgraph(graph, sampled_nodes)
#     motifs <- count_motifs(subgraph)
#     motif_counts_list[[i]] <- motifs
#     
#     # Update progress bar
#     pb$tick()
#     
#     # Perform garbage collection periodically to avoid memory issues
#     if (i %% 50 == 0) {
#       gc()
#     }
#   }
#   return(motif_counts_list)
# }
```
### Perform Subsampling and Motif Analysis

```{r}
# Set subsampling parameters
# sample_size <- 500
# num_samples <- 5000
# 
# # Subsampling for UC network
# motif_counts_uc <- subgraph_motif_counts_single(g_uc, sample_size, num_samples)
# 
# # Subsampling for HC network
# motif_counts_hc <- subgraph_motif_counts_single(g_hc, sample_size, num_samples)
```

```{r}
# # Convert list to data frame
# motif_data_uc <- do.call(rbind, lapply(motif_counts_uc, as.data.frame))
# motif_data_uc$group <- "UC"
# 
# motif_data_hc <- do.call(rbind, lapply(motif_counts_hc, as.data.frame))
# motif_data_hc$group <- "HC"
# 
# # Combine data
# motif_data <- rbind(motif_data_uc, motif_data_hc)
# 
# # Reshape data to long format
# motif_data_long <- melt(motif_data, id.vars = "group", 
#                         measure.vars = c("triangle", "v_shape", "three_star", "square"),
#                         variable.name = "motif_type", value.name = "count")
# 
# # Plot motif count distributions
# ggplot(motif_data_long, aes(x = group, y = count, fill = motif_type)) +
#   geom_violin(trim = FALSE, position = position_dodge(width = 0.75)) +
#   geom_boxplot(width = 0.1, position = position_dodge(width = 0.75), outlier.shape = NA) +
#   theme_minimal() +
#   labs(title = "Motif Counts Distribution",
#        x = "Group", y = "Normalized Motif Counts") +
#   scale_fill_manual(values = c("triangle" = "red", "v_shape" = "yellow", "three_star" = "green", "square" = "blue"))

```
##  Implementation of Multivariate Inference of Network Moments by Subsampling

```{r}
# 设置阈值
threshold <- .5  # 您可以根据需要调整阈值

# UC 组网络构建
#adjacency_UC <- adjacency(datExpr_UC_cleaned, power = softPower_UC, type = "signed")
# 将邻接矩阵二值化（基于指定的阈值）
adjacency_UC_binary <- (adjacency_UC > threshold) * 1
g_uc <- graph_from_adjacency_matrix(adjacency_UC_binary, mode = "undirected", diag = FALSE)
g_uc <- simplify(g_uc)

# HC 组网络构建
#adjacency_HC <- adjacency(datExpr_HC_cleaned, power = softPower_HC, type = "signed")
adjacency_HC_binary <- (adjacency_HC > threshold) * 1
g_hc <- graph_from_adjacency_matrix(adjacency_HC_binary, mode = "undirected", diag = FALSE)
g_hc <- simplify(g_hc)
```


### Motif Counting with Edge Weights
Modify the motif counting function to account for edge weights. For weighted networks, motif counts can be adjusted by incorporating edge weights, often by taking the geometric mean of the weights in the motif.
```{r}
# 定义基于拓扑的基序计数函数
count_motifs_unweighted <- function(graph) {
  num_nodes <- vcount(graph)
  
  # 初始化计数
  motif_counts <- list(
    triangle = 0,
    v_shape = 0,
    three_star = 0,
    square = 0
  )
  
  if (num_nodes < 3) {
    return(motif_counts)
  }
  
  # 计算三角形
  triangle_counts <- count_triangles(graph)
  total_triangles <- sum(triangle_counts) / 3  # 每个三角形被计数三次
  motif_counts$triangle <- total_triangles
  
  # 度数
  degrees <- degree(graph)
  
  # 计算 V 形（2 星）
  total_vshapes <- sum(choose(degrees, 2)) - 3 * total_triangles  # 减去三角形中的边
  motif_counts$v_shape <- total_vshapes
  
  # 计算 3 星
  total_three_stars <- sum(choose(degrees, 3))
  motif_counts$three_star <- total_three_stars
  
  # 计算四边形（square）
  if (num_nodes >= 4) {
    adj <- as_adj(graph, sparse = FALSE)
    adj2 <- adj %*% adj
    adj2_adj2 <- adj2 * adj2
    square_count <- sum(adj2_adj2) / 2 - sum(diag(adj2_adj2)) / 2
    total_squares <- square_count / 8  # 每个四边形被计数 8 次
    motif_counts$square <- total_squares
  }
  
  return(motif_counts)
}

```

```{r}
# 定义单线程的子图采样和基序计数函数（带进度条）
subgraph_motif_counts_single <- function(graph, sample_size, num_samples) {
  motif_counts_list <- vector("list", num_samples)
  
  # 创建进度条
  pb <- txtProgressBar(min = 0, max = num_samples, style = 3)
  
  for (i in 1:num_samples) {
    set.seed(i)  # 可选：设置种子以确保可重复性
    sampled_nodes <- sample(V(graph)$name, sample_size)
    subgraph <- induced_subgraph(graph, sampled_nodes)
    counts <- count_motifs_unweighted(subgraph)
    motif_counts_list[[i]] <- counts
    
    # 更新进度条
    setTxtProgressBar(pb, i)
  }
  
  # 关闭进度条
  close(pb)
  
  return(motif_counts_list)
}

```


```{r}
# 设置采样参数
sample_size <- 500
num_samples <- 5000

# 对 UC 网络进行子采样和基序计数
motif_counts_uc <- subgraph_motif_counts_single(g_uc, sample_size, num_samples)
# 对 HC 网络进行子采样和基序计数
motif_counts_hc <- subgraph_motif_counts_single(g_hc, sample_size, num_samples)
```
### 计算 U 统计量并进行归一化：
```{r}
# 计算 U 统计量并进行归一化
compute_normalized_U_statistic_motif <- function(motif_counts_list, motif_name, sample_size, network_size) {
  # 从子样本中获取计数
  counts <- sapply(motif_counts_list, function(x) x[[motif_name]])
  
  # 计算缩放因子（在对数空间）
  k <- switch(motif_name,
              "triangle" = 3,
              "v_shape" = 3,
              "three_star" = 4,
              "square" = 4)
  
  # 调整后的 U 统计量（在对数空间）
  scaling_factor_log <- lchoose(network_size, k) - lchoose(sample_size, k)
  estimated_total_count <- mean(counts) * exp(scaling_factor_log)
  
  # 计算可能的基序总数（在对数空间）
  total_possible_motifs_log <- switch(motif_name,
    "triangle" = lchoose(network_size, 3),
    "v_shape" = log(network_size) + lchoose(network_size - 1, 2),  # 近似
    "three_star" = log(network_size) + lchoose(network_size - 1, 3),
    "square" = lchoose(network_size, 4) + log(3)
  )
  
  total_possible_motifs <- exp(total_possible_motifs_log)
  
  # 归一化估计的总计数
  normalized_count <- estimated_total_count / total_possible_motifs
  
  return(normalized_count)
}

# 计算每个基序的归一化 U 统计量
network_size_uc <- vcount(g_uc)
network_size_hc <- vcount(g_hc)
motifs <- c("triangle", "v_shape", "three_star", "square")

normalized_u_stats_uc <- sapply(motifs, function(motif) {
  compute_normalized_U_statistic_motif(motif_counts_uc, motif, sample_size, network_size_uc)
})
names(normalized_u_stats_uc) <- motifs

normalized_u_stats_hc <- sapply(motifs, function(motif) {
  compute_normalized_U_statistic_motif(motif_counts_hc, motif, sample_size, network_size_hc)
})
names(normalized_u_stats_hc) <- motifs
```

```{r}
# 将归一化计数组合成数据框
normalized_counts <- data.frame(
  Motif = motifs,
  UC = normalized_u_stats_uc,
  HC = normalized_u_stats_hc
)
print("归一化的基序计数：")
print(normalized_counts)

# 可视化归一化的基序计数
normalized_counts_long <- melt(normalized_counts, id.vars = "Motif", variable.name = "Group", value.name = "Normalized_Count")

ggplot(normalized_counts_long, aes(x = Motif, y = Normalized_Count, fill = Group)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  theme_minimal() +
  labs(title = "归一化的基序计数比较", x = "基序类型", y = "归一化计数") +
  scale_fill_manual(values = c("UC" = "blue", "HC" = "red"))
```
```{r}
# 准备计数矩阵和标签
# 将基序计数列表转换为矩阵
counts_matrix_uc <- do.call(rbind, lapply(motif_counts_uc, function(x) unlist(x)[motifs]))
counts_matrix_hc <- do.call(rbind, lapply(motif_counts_hc, function(x) unlist(x)[motifs]))

# 将计数矩阵转换为数据框并添加组标签
counts_matrix_uc_df <- as.data.frame(counts_matrix_uc)
counts_matrix_hc_df <- as.data.frame(counts_matrix_hc)

counts_matrix_uc_df$Group <- "UC"
counts_matrix_hc_df$Group <- "HC"

# 合并数据框
counts_combined <- rbind(counts_matrix_uc_df, counts_matrix_hc_df)

# 提取 group_labels
group_labels <- counts_combined$Group

# 进行 Bootstrap 检验
bootstrap_test <- function(counts_combined, num_bootstrap, motifs) {
  n_uc <- sum(counts_combined$Group == "UC")
  n_hc <- sum(counts_combined$Group == "HC")
  
  diff_means <- numeric(num_bootstrap)
  
  for (b in 1:num_bootstrap) {
    # 采样 UC 和 HC 组的索引
    uc_indices <- sample(which(counts_combined$Group == "UC"), n_uc, replace = TRUE)
    hc_indices <- sample(which(counts_combined$Group == "HC"), n_hc, replace = TRUE)
    
    # 使用采样的索引获取样本
    sample_uc <- counts_combined[uc_indices, motifs]
    sample_hc <- counts_combined[hc_indices, motifs]
    
    # 计算均值差异
    diff_perm <- colMeans(sample_uc) - colMeans(sample_hc)
    diff_means[b] <- sum(diff_perm^2)
  }
  
  # 计算观察到的均值差异
  observed_diff <- colMeans(counts_combined[counts_combined$Group == "UC", motifs]) - 
                   colMeans(counts_combined[counts_combined$Group == "HC", motifs])
  observed_stat <- sum(observed_diff^2)
  
  p_value <- mean(diff_means >= observed_stat)
  return(p_value)
}

# 运行 Bootstrap 检验
num_bootstrap <- 10000  # 根据需要调整
p_value_bootstrap <- bootstrap_test(counts_combined, num_bootstrap, motifs)
cat("Bootstrap 检验的 p 值：", p_value_bootstrap, "\n")
```

## 7. Module Identification using Dynamic Tree Cut

### 7.1. UC Group Modules

```{r}
# Module identification using dynamic tree cut
dynamicMods_UC <- cutreeDynamic(dendro = geneTree_UC, distM = dissTOM_UC,
                                deepSplit = 2, pamRespectsDendro = FALSE,
                                minClusterSize = 30)

# Convert numeric labels into colors
dynamicColors_UC <- labels2colors(dynamicMods_UC)

# Plot the dendrogram and module colors
plotDendroAndColors(geneTree_UC, dynamicColors_UC, "Dynamic Tree Cut",
                    dendroLabels = FALSE, hang = 0.03,
                    addGuide = TRUE, guideHang = 0.05,
                    main = "Gene dendrogram and module colors (UC)")
```

### 7.2. HC Group Modules
```{r}
# Module identification using dynamic tree cut
dynamicMods_HC <- cutreeDynamic(dendro = geneTree_HC, distM = dissTOM_HC,
                                deepSplit = 2, pamRespectsDendro = FALSE,
                                minClusterSize = 30)

# Convert numeric labels into colors
dynamicColors_HC <- labels2colors(dynamicMods_HC)

# Plot the dendrogram and module colors
plotDendroAndColors(geneTree_HC, dynamicColors_HC, "Dynamic Tree Cut",
                    dendroLabels = FALSE, hang = 0.03,
                    addGuide = TRUE, guideHang = 0.05,
                    main = "Gene dendrogram and module colors (HC)")

```


### 8. Compare Module Assignments between UC and HC

We compare the module assignments of genes between the two groups.

```{r}
# Create a data frame of gene modules in both groups
module_comparison <- data.frame(
  Gene = common_genes_final,
  Module_UC = dynamicColors_UC,
  Module_HC = dynamicColors_HC
)

# Calculate the contingency table
contingency_table <- table(module_comparison$Module_UC, module_comparison$Module_HC)
print(contingency_table)
```
```{r}
# Plot the heatmap
pheatmap(contingency_table, cluster_rows = FALSE, cluster_cols = FALSE,
         display_numbers = TRUE, main = "Module Overlap between UC and HC")

```
## 9. Module Eigengene Analysis
### 9.1. Calculate Module Eigengenes
```{r}
# UC group
MEList_UC <- moduleEigengenes(datExpr_UC_cleaned, colors = dynamicColors_UC)
MEs_UC <- MEList_UC$eigengenes
MEs_UC <- orderMEs(MEs_UC)

# HC group
MEList_HC <- moduleEigengenes(datExpr_HC_cleaned, colors = dynamicColors_HC)
MEs_HC <- MEList_HC$eigengenes
MEs_HC <- orderMEs(MEs_HC)

```

### 9.2. Compare Module Eigengenes between Groups
Since modules may not correspond directly between groups, we can compare the expression patterns of common modules or perform cross-group analysis.

```{r}
# For modules with the same color names, compare eigengenes
common_modules <- intersect(names(MEs_UC), names(MEs_HC))
```

```{r}
# Prepare data for plotting
MEs_UC$Group <- "UC"
MEs_HC$Group <- "HC"

# Combine data
MEs_combined <- rbind(MEs_UC[, c(common_modules, "Group")], MEs_HC[, c(common_modules, "Group")])

# Melt data for ggplot
MEs_melted <- melt(MEs_combined, id.vars = "Group")

# Plot module eigengenes by group
ggplot(MEs_melted, aes(x = Group, y = value, fill = Group)) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  theme_minimal() +
  labs(title = "Module Eigengene Expression by Group",
       x = "Group", y = "Module Eigengene") +
  stat_compare_means(method = "t.test", label = "p.format")

```
```{r}
# 定义导出函数
export_graph_edges <- function(graph, file_name) {
  # 获取边列表，包含 source 和 target 节点
  edge_list <- as_data_frame(graph, what = "edges")
  colnames(edge_list) <- c("source", "target")  # 命名为 source 和 target
  
  # 将边列表导出为 CSV 文件
  write.csv(edge_list, file = file_name, row.names = FALSE)
}

# 导出 g_uc 和 g_hc
export_graph_edges(g_uc, "S://network//hcuc//g_uc_pearson.csv")
export_graph_edges(g_hc, "S://network//hcuc//g_hc_pearson.csv")
```

```{r}
# Save all objects in the global environment to an RData file without compression
save(list = ls(), file = "S://network//hcuc//pearson.RData", compress = FALSE)
```


## 10. Statistical Analysis of Module Differences
We perform statistical tests to see if module eigengenes differ significantly between UC and HC groups.



